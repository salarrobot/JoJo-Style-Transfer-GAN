{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3f7af31-8cff-41f6-bb90-865d5ed8bee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è  cuda\n",
      "GPU: NVIDIA GeForce GTX 1050\n",
      "\n",
      "‚ö° LIGHT: 128x128, 20 epochs, batch 2\n",
      "‚úÖ Ready!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools, shutil\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è  {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# ‚ö° LIGHT SETTINGS\n",
    "IMG_SIZE = 128\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "os.makedirs('outputs/samples', exist_ok=True)\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "print(f\"\\n‚ö° LIGHT: {IMG_SIZE}x{IMG_SIZE}, {EPOCHS} epochs, batch {BATCH_SIZE}\")\n",
    "print(\"‚úÖ Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca464ba-0bec-45fa-80b0-e11fa1beb90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5000 real, 5000 anime\n",
      "‚úÖ 2500 batches per epoch\n"
     ]
    }
   ],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, real_dir, anime_dir, transform):\n",
    "        # Only use 5000 images for speed!\n",
    "        real_files = [f for f in os.listdir(real_dir) if f.endswith(('.jpg','.png'))][:5000]\n",
    "        anime_files = [f for f in os.listdir(anime_dir) if f.endswith(('.jpg','.png'))][:5000]\n",
    "        \n",
    "        self.real = [os.path.join(real_dir, f) for f in real_files]\n",
    "        self.anime = [os.path.join(anime_dir, f) for f in anime_files]\n",
    "        self.transform = transform\n",
    "        print(f\"Using {len(self.real)} real, {len(self.anime)} anime\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(len(self.real), len(self.anime))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        r = Image.open(self.real[idx % len(self.real)]).convert('RGB')\n",
    "        a = Image.open(self.anime[idx % len(self.anime)]).convert('RGB')\n",
    "        return {'real': self.transform(r), 'anime': self.transform(a)}\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "dataset = SimpleDataset('train/Real_Faces', 'train/Anime_Faces', transform)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "print(f\"‚úÖ {len(loader)} batches per epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf4fc8f4-b15f-4807-aed7-2f3fd2d9a199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Models: 194,051 params (LIGHT!)\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Very simple encoder-decoder\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 7, padding=3), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, 2, 1), nn.ReLU()\n",
    "        )\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 3, 2, 1, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 3, 2, 1, 1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 3, 7, padding=3), nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.dec(self.enc(x))\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, 2, 1), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 1, 4, 1, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "G_AB = Generator().to(device)\n",
    "G_BA = Generator().to(device)\n",
    "D_A = Discriminator().to(device)\n",
    "D_B = Discriminator().to(device)\n",
    "\n",
    "opt_G = optim.Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=0.0002, betas=(0.5, 0.999))\n",
    "opt_D_A = optim.Adam(D_A.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "opt_D_B = optim.Adam(D_B.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "L_GAN = nn.MSELoss()\n",
    "L_cyc = nn.L1Loss()\n",
    "L_id = nn.L1Loss()\n",
    "\n",
    "print(f\"‚úÖ Models: {sum(p.numel() for p in G_AB.parameters()):,} params (LIGHT!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cc13cf-51f3-45ac-acde-c3307182bb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Training 20 epochs...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f37e6f9781a472fb5c1739f43a9c6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c01904476d4b7db56aa84a108d0020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7de808db704923a30f016a00cad7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eae1e7e81874dbf95ae140a890bb7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e7acca6eaf4241904392aef6d151a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Sample saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3416e90d3a46c0867d046535412e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f999b0f1aafe43bf872808f91804fd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "accafafa8c544ebb8767b3817d3cbdfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2c372a7a9c49bd9cbdc19ab12c7810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849ec1cf27e34cc8b21bc93e22154b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Sample saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3be89dfbdf42faa5758f941878a40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aadaba8375245799284802b0a789177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b073d349d15945bc873c27d95361b7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2002332537548ef81b93d24de1f0539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21cab729fba494b858366db9d7f721d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Sample saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc119b468e8140c7a48a4f289bfaa853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b590cd43dca34b2387abf881e71c0113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8330814abf704241b36bd94a5715f7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a33b174f98848068769dce88c6bf77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7b9cd929384437927551f57c8b7d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/20:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"\\nüöÄ Training {EPOCHS} epochs...\\n\")\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {ep+1}/{EPOCHS}\")\n",
    "    \n",
    "    for batch in pbar:\n",
    "        rA = batch['anime'].to(device)\n",
    "        rB = batch['real'].to(device)\n",
    "        \n",
    "        valid = torch.ones((rA.size(0), 1, 15, 15), device=device)\n",
    "        fake = torch.zeros((rA.size(0), 1, 15, 15), device=device)\n",
    "        \n",
    "        # Gen\n",
    "        opt_G.zero_grad()\n",
    "        fB = G_AB(rB)\n",
    "        fA = G_BA(rA)\n",
    "        \n",
    "        l_id = (L_id(G_BA(rA), rA) + L_id(G_AB(rB), rB)) / 2\n",
    "        l_gan = (L_GAN(D_A(fB), valid) + L_GAN(D_B(fA), valid)) / 2\n",
    "        l_cyc = (L_cyc(G_BA(fB), rB) + L_cyc(G_AB(fA), rA)) / 2\n",
    "        \n",
    "        l_G = l_gan + 10*l_cyc + 5*l_id\n",
    "        l_G.backward()\n",
    "        opt_G.step()\n",
    "        \n",
    "        # Disc\n",
    "        opt_D_A.zero_grad()\n",
    "        l_DA = (L_GAN(D_A(rA), valid) + L_GAN(D_A(fB.detach()), fake)) / 2\n",
    "        l_DA.backward()\n",
    "        opt_D_A.step()\n",
    "        \n",
    "        opt_D_B.zero_grad()\n",
    "        l_DB = (L_GAN(D_B(rB), valid) + L_GAN(D_B(fA.detach()), fake)) / 2\n",
    "        l_DB.backward()\n",
    "        opt_D_B.step()\n",
    "        \n",
    "        pbar.set_postfix({'G': f'{l_G.item():.2f}', 'D': f'{(l_DA+l_DB).item()/2:.2f}'})\n",
    "    \n",
    "    if (ep+1) % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "            save_image((torch.cat([rB[:2], fB[:2]])+1)/2, f'outputs/samples/ep{ep+1}.png', nrow=2)\n",
    "        print(f\"  ‚úì Sample saved\")\n",
    "\n",
    "torch.save(G_AB.state_dict(), 'checkpoints/G_AB_final.pt')\n",
    "print(\"\\nüéâ Done! Saved to checkpoints/G_AB_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76680bc1-b638-4dc1-b9f0-70de4697186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# INFERENCE: Generate JoJo-style Images\n",
    "# ========================================\n",
    "\n",
    "# Configuration - Update TEST_DIR when test set is released\n",
    "TEST_DIR = 'test'  # <-- UPDATE THIS PATH when you get the test set\n",
    "OUTPUT_DIR = 'results'\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "G_AB.eval()\n",
    "\n",
    "# Transform for test images\n",
    "test_trans = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# Get test images\n",
    "if not os.path.exists(TEST_DIR):\n",
    "    print(f\"‚ö†Ô∏è  WARNING: {TEST_DIR} folder not found!\")\n",
    "    print(f\"Please create the folder and add test images when they are released.\\n\")\n",
    "    tests = []\n",
    "else:\n",
    "    tests = [f for f in os.listdir(TEST_DIR) if f.endswith(('.jpg','.png'))]\n",
    "    print(f\"Found {len(tests)} test images in {TEST_DIR}/\")\n",
    "\n",
    "if len(tests) > 0:\n",
    "    print(f\"Generating {len(tests)} JoJo-style images...\\n\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for name in tqdm(tests):\n",
    "            # Load and transform image\n",
    "            img = test_trans(Image.open(f'{TEST_DIR}/{name}').convert('RGB')).unsqueeze(0).to(device)\n",
    "            \n",
    "            # Generate JoJo-style image\n",
    "            out = G_AB(img)\n",
    "            \n",
    "            # Save (denormalize from [-1,1] to [0,1])\n",
    "            save_image((out+1)/2, f'{OUTPUT_DIR}/{name}')\n",
    "    \n",
    "    print(f\"\\n‚úÖ Generated {len(tests)} JoJo-style images in {OUTPUT_DIR}/\")\n",
    "else:\n",
    "    print(\"No test images found. Waiting for test set release...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3001700f-4729-4029-898c-947341fdf0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CREATE SUBMISSION PACKAGE\n",
    "# ========================================\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "\n",
    "# Check if we have results\n",
    "if not os.path.exists(OUTPUT_DIR) or len(os.listdir(OUTPUT_DIR)) == 0:\n",
    "    print(\"‚ö†Ô∏è  No results found! Please run inference first.\")\n",
    "else:\n",
    "    # Show preview of first 4 results\n",
    "    result_files = [f for f in os.listdir(OUTPUT_DIR) if f.endswith(('.jpg','.png'))][:4]\n",
    "    \n",
    "    if len(result_files) >= 4:\n",
    "        fig, ax = plt.subplots(2, 4, figsize=(16, 8))\n",
    "        for i in range(4):\n",
    "            ax[0,i].imshow(Image.open(f'{TEST_DIR}/{result_files[i]}'))\n",
    "            ax[0,i].set_title('Original')\n",
    "            ax[0,i].axis('off')\n",
    "            ax[1,i].imshow(Image.open(f'{OUTPUT_DIR}/{result_files[i]}'))\n",
    "            ax[1,i].set_title('JoJo Style')\n",
    "            ax[1,i].axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('outputs/preview.png')\n",
    "        plt.show()\n",
    "    \n",
    "    # Create submission folder structure\n",
    "    SUBMISSION_DIR = 'submission'\n",
    "    os.makedirs(SUBMISSION_DIR, exist_ok=True)\n",
    "    \n",
    "    # Copy model file\n",
    "    if os.path.exists('checkpoints/G_AB_final.pt'):\n",
    "        shutil.copy('checkpoints/G_AB_final.pt', f'{SUBMISSION_DIR}/best_generator.pt')\n",
    "        print(\"‚úÖ Copied model: best_generator.pt\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Warning: Model checkpoint not found!\")\n",
    "    \n",
    "    # Copy test results\n",
    "    if os.path.exists(f'{SUBMISSION_DIR}/test_results'):\n",
    "        shutil.rmtree(f'{SUBMISSION_DIR}/test_results')\n",
    "    shutil.copytree(OUTPUT_DIR, f'{SUBMISSION_DIR}/test_results')\n",
    "    print(f\"‚úÖ Copied {len(tests)} images to test_results/\")\n",
    "    \n",
    "    # Create README\n",
    "    with open(f'{SUBMISSION_DIR}/README.md', 'w') as f:\n",
    "        f.write(f\"\"\"# JoJo Style Transfer - Homework 2\n",
    "\"\"\")\n",
    "    \n",
    "    # Create ZIP file for submission\n",
    "    zip_filename = 'submission.zip'\n",
    "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # Add all files in submission folder\n",
    "        for root, dirs, files in os.walk(SUBMISSION_DIR):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, SUBMISSION_DIR)\n",
    "                zipf.write(file_path, arcname)\n",
    "    \n",
    "    print(f\"\\nüì¶ SUBMISSION PACKAGE READY!\")\n",
    "    print(f\"   ‚úÖ {SUBMISSION_DIR}/best_generator.pt\")\n",
    "    print(f\"   ‚úÖ {SUBMISSION_DIR}/test_results/ ({len(tests)} images)\")\n",
    "    print(f\"   ‚úÖ {SUBMISSION_DIR}/README.md\")\n",
    "    print(f\"   ‚úÖ {zip_filename} (ready to upload!)\")\n",
    "    print(f\"\\nüí° Upload '{zip_filename}' to Moodle\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
